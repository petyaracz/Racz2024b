---
title: "Phonological categorisation models for Hungarian morphological patterns"
author: "Rácz, Péter"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
# sed -i 's/Readme/ApocalypticLog/g' *.Rmd

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE, fig.path = 'figures/', fig.width = 8, fig.height = 8)

# set wd in md
knitr::opts_knit$set(root.dir = '~/Github/Racz2024b')
setwd('~/Github/Racz2024b')

set.seed(1337)

library(tidyverse)
library(glue)
library(magrittr)
library(knitr)
library(ggthemes)
library(lme4)
library(patchwork)
library(ggrepel)
library(stringdist)

# some of this takes a lot of iterations
no_cores <- future::availableCores() - 1
future::plan(future::multisession, workers = no_cores)

# source helper functions
source('code/helper.R')

# other functions

# -- fun -- #

# build 3d mds from dist table
makeDistMDS = function(dat){
  dat2 = dat |>
    dplyr::filter(segment1 != ' ', segment2 != ' ')
  dat_matrix = dat2 |>
    tidyr::pivot_wider(names_from = segment2, values_from = dist) |> 
    dplyr::select(-segment1) |> 
    as.matrix()
  dat_mds = stats::cmdscale(dat_matrix, k = 3)
  tidyr::tibble(
    x = dat_mds[,1],
    y = dat_mds[,2],
    z = dat_mds[,3],
    label = unique(dat2$segment1)
  ) 
}

# wrapper for KNN that filters for variation
wrapKNN = function(dat, distance_type, my_variation, var_p, var_s, var_k){
dat |>
  dplyr::filter(variation == my_variation) |>
  KNN(distance_type = distance_type, var_s = var_s, var_k = var_k, var_p = var_p)
}
# wrapper for GCM that filters for variation
wrapGCM = function(dat, distance_type, my_variation, var_s, var_p){
dat |>
  dplyr::filter(variation == my_variation) |>
  GCM(distance_type = distance_type, var_s = var_s, var_p = var_p)
}

# combine result tibbles with test responses
combineWithTest = function(dat){
  test %>% 
  rename(test = string) %>% 
  select(test,resp1,resp2,log_odds) %>% 
  inner_join(dat, by = 'test')
}

# fit a model that predicts response rations from category labels and pulls the summary
testAccuracy = function(dat){
  fit = glm(cbind(resp1,resp2) ~ 1 + category_high, data = dat, family = binomial(link = 'logit'))
  broom::tidy(fit) %>% 
    filter(term == 'category_high') %>% 
    mutate(sig = case_when(
      p.value < .001 ~ '***',
      p.value < .01 ~ '**',
      p.value < .05 ~ '*',
      p.value >= .05 ~ 'ns.'
      )
    )
}
```

In this readme, we go through a way of measuring distance between words based on natural classes that are, in turn, based on segmental similarity. Then we use this in two categorisation models to predict what people do in a Wug task with three variable patterns of Hungarian morphology.

## TOC

1. Generate natural classes from a language's phonological feature matrix
2. Generate segment-distances from the natural classes
3. Generate word-distances from the segment-distances using a word aligner
4. Generate categories from the word distances and an algo

```{r preload}
# features
h = read_tsv('dat/feature_matrices/siptar_torkenczy_toth_racz_hungarian.tsv')
# nat classes
nch = read_tsv('dat/natural_classes/siptar_torkenczy_toth_racz_hungarian_nc.tsv')
# segment distance lookup
lookup_h = read_tsv('dat/segmental_distances/siptar_torkenczy_toth_racz_hungarian_dt.tsv')
# training and test data
test = read_tsv('dat/training_sets/test_set.tsv')
training = read_tsv('dat/training_sets/training_set.tsv')
# alignments of training x test data across three variations
# alignments_lakok = read_tsv('dat/alignments/alignments_lakok.tsv')
# alignments_cselekszenek = read_tsv('dat/alignments/alignments_cselekszenek.tsv')
# alignments_hotelban = read_tsv('dat/alignments/alignments_hotelban.tsv')
word_distance = read_tsv('dat/alignments/word_distances.tsv')

# this has to be done each time this is loaded
lookup_h %<>% mutate(across(-dist, ~ ifelse(is.na(.x), " ", .x)))
```

## Quick start

We do this below but in detail:

```{r quick_start, echo = T, eval = F}
# a. generate natural classes

nch = h |>
  generateNaturalClasses()

# b. build distance table for pairwise segment comparisons

lookup_h = buildDistTable(h, nch) |>
  addLevenshtein()

# c. align test and target words to find best phon-based alignment, here, for the 'lakok/lakom' variation. this takes ages.

alignments_lakok = runLookup(test_l,training_l,lookup_h)

# d. get distance based on best alignment, here, for lakok. join back with training data.

word_distance_lakok = alignments_lakok |>
  dplyr::distinct(test,training,total_dist) |>
  dplyr::rename(phon_dist = total_dist) |>
  dplyr::left_join(training, join_by('training' == 'string'))

# e. use the paired data to fit some sort of a phon distance based learning model, here, a KNN

# you can use a wrapper function to do a-e:
KNNwrapper(test = test, training = training, feature_matrix = fm, my_distance = 'phon', my_s = .1, my_k = 3, my_p = 1)

# you can use the wrapper function to use some other distance and skip the whole alignment bit:
KNNwrapper(test = test, training = training, feature_matrix = fm, my_distance = 'jaccard', my_s = .1, my_k = 3, my_p = 1)

```

## 1. Generate natural classes

The feature matrix was adapted from Siptár and Törkenczy (2000). "ṯ", "ḏ", and "ṉ" are the palatal stops. "c" is "ts". Here is a sample of the feature matrix.

```{r feature_matrix}
h %>% 
  sample_n(10) %>% 
  # replace 0 with -
  mutate(across(-segment, ~ ifelse(.x == 0, '-', .x))) %>%
  # replace 1 with +
  mutate(across(-segment, ~ ifelse(.x == 1, '+', .x))) %>%
  # replace NA with " "
  mutate(across(-segment, ~ ifelse(is.na(.x), " ", .x))) %>%
  kable(caption = 'Table: Sample of the phonological feature matrix')
```

We turn it into underspecified natural class descriptions following Albrighty and Hayes (2003) and Frisch, Pierrehumbert, and Broe (2004).

```{r natural_classes_1, echo = T, eval = F}
nch = h |>
  generateNaturalClasses()

write_tsv(nch, 'dat/natural_classes/siptar_torkenczy_toth_racz_hungarian_nc.tsv')
```

Here's a sample of what the output looks like.

```{r natural_classes_2}
nch %>% 
  sample_n(10) %>% 
  kable(caption = 'Table: Sample of the natural classes')
```

## 2. Generate segment-distances from the natural classes

We use the natural classes to calculate segment distances and also add edit distances for the sake of completeness: Any segment vs any other segment has a distance of 0-1, any segment vs nothing has a distance of 1.

```{r segment_distances_1, echo = T, eval = F}
lookup_h = buildDistTable(h, nch) |>
  addLevenshtein()

write_tsv(lookup_h, 'dat/segmental_distances/siptar_torkenczy_toth_racz_hungarian_dt.tsv')
```

Here's a sample of what the output looks like.

```{r segment_distances_2}
lookup_h %>% 
  # replace all NA with ' ' in all columns
  mutate(across(all_of(c("segment1","segment2")), ~ ifelse(is.na(.x), ' ', .x))) %>% 
  sample_n(10) %>% 
  kable(digits = 2, caption = 'Table: Sample of the segmental distances')
```

Distances between objects can be turned into a map of objects using multidimensional scaling. Here's what segmental distances look like in the output as a map, across 3 dimensions.

```{r segment_distances_3, fig.width = 8, fig.height = 8}
# some innocent fun
mds_h = makeDistMDS(lookup_h)
# spec theme
my_theme = theme(
    axis.text.x = ggplot2::element_blank(),
    axis.text.y = ggplot2::element_blank(),
    axis.ticks = ggplot2::element_blank(),
    plot.title = ggplot2::element_blank()
  )
# plot mds_h with text label
p1 = mds_h |>
  ggplot(aes(x = x, y = y, label = label)) +
  geom_label_repel(max.overlaps = 11) +
  theme_few() +
  my_theme
p2 = mds_h |>
  ggplot(aes(x = y, y = z, label = label)) +
  geom_label_repel(max.overlaps = 11) +
  theme_few() +
  my_theme
p3 = mds_h |>
  ggplot(aes(x = x, y = z, label = label)) +
  geom_label_repel(max.overlaps = 11) +
  theme_few() +
  my_theme
(p1 + p2) / (plot_spacer() + p3) + plot_annotation(title = 'Figure: Segmental distances in 3 dimensions')

```

These three dimensions don't exactly match to place or manner of articulation, but we can recognise patterns. The top left panel splits segments into vowels, non-coronals, coronal stops, and coronal continuants. The top right panel shows velars, labials, and coronals, mixing in the vowels, which share place of articulation features with the consonants. The bottom right panel splits vowels from consonants, and shows consonants in a continuum from labial and dorsal to coronal.

## 3. Generate word-distances from the segment-distances using a word aligner

We want to find the alignment between word 1 and word 2 where the pairwise comparison of their segments yields the smallest total distance. We can skip slots. This is a good alignment:

```
a s t r á l
o s t   á j 
```

This isn't:

```
a s t r á l
o s t á j 
```

For each word pair, we do every conceivable alignment and pick the one with the shortest total distance. This will be the pair with the best alignment. This process is resource intensive. To run it, we need the two words and the lookup table generated in step 2. The resulting table shows the two strings in their bestalignment (col 1 and 2), the distances between the segments (dist, this is 0 for identical segments and 1 for deletion / insertion) and the total distance (sum of dist, which is the same value for the whole aignment).

```{r word_distances_1, echo = T}
alignWords('astrál', 'ostáj', lookup_h) %>% 
  kable(digits = 2, caption = 'Table: Sample alignment 1')
```

Some of this is less intuitive, because sometimes the best alignment is ceteris paribus not the one you'd expect, see:

```{r word_distances_2, echo = T}
alignWords('astalka', 'astrál', lookup_h) %>% 
  kable(digits = 2, caption = 'Table: Sample alignment 2')
```

Apparently comparing the final `ka$` to the final `ál$` is a better bargain than skipping 1 segment and gaining a penalty of 1 and then comparing `ka $` to ` ál$`.

This is based on Albrighty and Hayes (2003) and Dawdy-Hesterberg and Pierrehumbert (2014).

## 4. Generate categories from the word distances and an algorithm

I have some training and test data for three variable patterns in Hungarian. See the preprint for details.

a. inflectional: 1sg.indef variation: lakok/lakom ("I live")
b. inflectional: vowel deletion: cselekszenek/cselekednek ("they act")
c. declensional: vowel harmony: hotelban/hotelben ("in the hotel")

- training data come from Hungarian webcorpus 2.
- test data come from a wug task where people responded to prompts in a forced-choice format. about 30 people responded to each prompt. they came from a student pool. See the preprint for details. (The preprint only talks about 1 and 2 right now, but it covers methods and ethics for 3 as well.)

Training data look like this:

```{r training_data_1}
training %>% 
  group_by(variation,category) %>% 
  sample_n(2) %>% 
  kable(digits = 2, caption = 'Table: Sample of the training data')
```

The category labels are pretty arbitrary.

For 'cselekszenek/cselekednek', verbs that end in `CCik$` are the "high" category and verbs that end in `CVCik$` are the "low" category. (This is slightly more complicated: some `CVCik$` verbs act like `CCik$` verbs with vowel-initial suffixes and these were put in the `CCik$` category.)

For 'hotelban/hotelben', the two variants are back or front vowel in the suffix -- but these vary across a range of suffixes, the suffixes themselves have different total frequencies, so I fit a mixed model predicting `cbind(freq1,freq2)` in the corpus with a stem and suffix intercept. I then extracted the stem random effects and split the distribution across the median. This is the "high" and "low" category. Nouns that prefer back suffixes are in the "high" category and nouns that prefer front suffixes are in the "low" category.

For 'lakok/lakom', there is one exponent that varies and you can count the two forms (lakok, lakom) per verb and calculate log odds, then split the distribution across the median.

Training data was restricted to exclude less frequent forms and very long forms. This is fairly arbitrary.

Test data look like this:

```{r test_data}
test %>% 
  group_by(variation) %>% 
  select(base,variation,variant1,variant2,resp1,resp2,string) %>% 
  sample_n(5) %>% 
  kable(digits = 2, caption = 'Table: Sample of the test data')

```

Test data were generated from corpus distributions using a syllabic constituent-based ngram model. The resulting words are somewhat onset-heavy (words in Hungarian can begin with `^sp` but maybe not this often). Note that for 'cselekszenek', the Wug prompts had a CC and CVC form, as both are possible (that being the point). We use the CC form to calculate distances. This is a semi-arbitrary decision: variable verbs have a CC and a CVC form. Stable CVC verbs never have a CC form. See the preprint for details.

`string` is transcribed using a simple converter that maps Hungarian orthography to IPA.

For each variation, you pair test and training words and calc word distance. For the verbs ('cselekszenek', 'lakok' types) you can drop the `ik$` ending as all verbs have it anyway.

```{r word_distances_3, echo = T, eval = F}
# this legitimately takes a while.

# set up test and training data
testl = filter(test, variation == 'lakok/lakom')
trainingl = filter(training, variation == 'lakok/lakom')
testcs = filter(test, variation == 'cselekszenek/cselekednek')
trainingcs = filter(training, variation == 'cselekszenek/cselekednek')
testh = filter(test, variation == 'hotelban/hotelben')
trainingh = filter(training, variation == 'hotelban/hotelben')

# run the lookup for all variations
alignments_lakok = runLookup(testl,trainingl,lookup_h)
alignments_cselekszenek = runLookup(testcs,trainingcs,lookup_h)
alignments_hotelban = runLookup(testh,trainingh,lookup_h)

# write_tsv(alignments_lakok, 'dat/alignments/alignments_lakok.tsv')
# write_tsv(alignments_cselekszenek, 'dat/alignments/alignments_cselekszenek.tsv')
# write_tsv(alignments_hotelban, 'dat/alignments/alignments_hotelban.tsv')
```

We now have best alignments for training : test data. These might be useful someday, like if we want to build a rule-based learner. They look like this. In the test col are three nonce words used in the Wug task. In the training col are three aligned training words. Segment 1 and 2 show the test and training words broken up in segments, in their best alignment. Dist shows segmental distances (this is the same as the table above). Total dist shows the total distance for the alignment, which is the sum of segmental distances. 

This is just three examples. Note that we deleted the verbal "ik" ending because that's the same everywhere and this speeds up computation.

```{r word_distances_4, eval = F}

keep = alignments_lakok %>%
  distinct(test,training) %>% 
  sample_n(3)

alignments_lakok %>% 
  inner_join(keep) %>%
  # replace NA with ' '
  mutate(segment1 = ifelse(is.na(segment1), ' ', segment1),
         segment2 = ifelse(is.na(segment2), ' ', segment2)) %>%
  kable(digits = 2)

# the same in a md Table: 
```


|test   |training |segment1 |segment2 | dist|  phon_dist|
|:------|:--------|:--------|:--------|----:|----------:|
|narádz |bábáškod |n        |b        | 0.84|       5.84|
|narádz |bábáškod |a        |á        | 0.58|       5.84|
|narádz |bábáškod |r        |b        | 0.94|       5.84|
|narádz |bábáškod |á        |á        | 0.00|       5.84|
|narádz |bábáškod |         |š        | 1.00|       5.84|
|narádz |bábáškod |d        |k        | 0.84|       5.84|
|narádz |bábáškod |         |o        | 1.00|       5.84|
|narádz |bábáškod |z        |d        | 0.63|       5.84|
|šalárz |kérked   |š        |k        | 0.86|       4.21|
|šalárz |kérked   |a        |é        | 0.81|       4.21|
|šalárz |kérked   |l        |r        | 0.12|       4.21|
|šalárz |kérked   |á        |k        | 0.92|       4.21|
|šalárz |kérked   |r        |e        | 0.88|       4.21|
|šalárz |kérked   |z        |d        | 0.63|       4.21|
|streml |vesőd    |s        |v        | 0.87|       5.11|
|streml |vesőd    |t        |e        | 0.95|       5.11|
|streml |vesőd    |r        |s        | 0.64|       5.11|
|streml |vesőd    |e        |ő        | 0.79|       5.11|
|streml |vesőd    |m        |d        | 0.86|       5.11|
|streml |vesőd    |l        |         | 1.00|       5.11|

Table: Example alignments

What we actually need is the total phonological distances.

```{r add_distance, eval = F, echo = F}
alignments_lakok_2 = alignments_lakok %>% 
  mutate(variation = 'lakok/lakom') %>% 
  distinct(test,training,phon_dist,variation)

alignments_hotelban_2 = alignments_hotelban %>% 
  mutate(variation = 'hotelban/hotelben') %>% 
  distinct(test,training,phon_dist,variation)

alignments_cselekszenek_2 = alignments_cselekszenek %>% 
  mutate(variation = 'cselekszenek/cselekednek') %>%
  distinct(test,training,phon_dist,variation)

word_distance = bind_rows(
  alignments_lakok_2,
  alignments_hotelban_2,
  alignments_cselekszenek_2
)

write_tsv(word_distance, 'dat/alignments/word_distances.tsv')
```

The final result looks like this:

```{r word_distances_5}

word_distance %>% 
  group_by(variation) %>% 
  sample_n(5) %>%
  select(test,training,variation,phon_dist) %>% 
  kable(digits = 2, caption = 'Table: Word distances for nonce words in the Wug task and their aligned training words.')
  
```

## 4. Model!

The nonce words got variable A or B responses in the Wug task and have a specific similarity to existing words in two categories: A and B. A and B are different for each word type ('cselekszenek', 'hotelban', 'lakok'). We want to see whether similarity to existing words predicts variable responses. 

Training categories are:

- cselekszenek/cselekednek: stable `CCik$` verbs are high, stable `CVCik$` verbs are low
- lakok/lakom: variable verbs above the median log odds of k/m in the corpus are high, others are low
- hotelban/hotelben: we aggregated over multiple suffixed variants to have a random intercept for each stem, those over the median of random intercepts are high, others low

Training sets were also slightly culled to include only more frequent verbs and shorter verbs. (see preprint and `training_preprocessor.R` for details).

```{r categorisation2, echo = F}
# same verb if variable might be in both categories, for cselekszenek. double check it please.

word_distance = training %>% 
  rename(training = string, training_label = base) %>%
  select(training,training_label,variation,category) %>% 
  inner_join(word_distance) %>% 
  distinct(test,training,training_label,variation,category,phon_dist)

word_distance = test %>%
  rename(test = string, test_label = base) %>%
  inner_join(word_distance)
```

The end result looks like this. This is distances between test words and training words and responses to test words and training word category.

```{r categorisation3}
word_distance %>% 
  group_by(variation,category) %>%
  sample_n(2) %>%
  select(test_label,training_label,category,phon_dist) %>% 
  kable(digits = 2, caption = 'Table: Word distances for nonce words in the Wug task and their aligned training words, with training word category and test word response log odds (large log odds: lot of "high" responses).')

```

### KNN

We categorise test words based on similarity with training words using a K-Nearest Neighbours algorithm. The algorithm calculates word distance using the formula `exp ( - dist / s ) ^ p`.

We try `k = [1,3,5,7,15]`, `p = [1,2]`, and `s = [.1,.3,.5,.7,.9]` and `dist = [edit distance, jaccard distance, phonological distance]`. Edit distance tallies up the number of edits needed to get from Word A to Word B. Jaccard distance is the set size of the intersect of segments in Word A and Word B divided by the set size of the union of segments in Word A and Word B. Phonological distance is the whole setup above.

A regular old KNN compares the target word to the nearest n words and counts category labels. So if this is 3 words and they are "high", "high", "low", the target word is categorised as "high". My KNN outputs the mean category label, which, in the example, would be .66.

For each test word, we get a KNN prediction for each parameter combination. Then we fit a GLM that predicts how people "voted" on the word (like, 15 picked variant A and 20 picked variant B) from the model's category weight. We then grab the term "category: high" from the model and take the est, std error, z value (statistic), and p value. These express how well the KNN weights predict whether more people picked variant A or B. We compare models using the z value (statistic), which favours the least noise over the largest effect.

```{r categorisation4, echo = T}

# set up parameters
my_parameters_1 = crossing(
  var_p = c(1,2),
  var_k = c(1,3,5,7,15),
  var_s = c(.1,.3,.5,.7,.9),
  distance_type = c('edit','jaccard','phon'),
  variation = c('lakok/lakom','hotelban/hotelben','cselekszenek/cselekednek')
)

# run 450 models, parallelised, add prediction tibbles to each model
my_knns = my_parameters_1 %>% 
  mutate(
    knn = furrr::future_pmap(list(variation,distance_type,var_p,var_s,var_k), ~ wrapKNN(
      dat = word_distance,
      my_variation = ..1,
      distance_type = ..2,
      var_p = ..3,
      var_s = ..4,
      var_k = ..5
      )
    )
  )

# combine with test and calc accuracy
my_knns %<>% 
  mutate(
    knn2 = map(knn,combineWithTest),
    accuracy = map(knn2,testAccuracy)
  )

my_knns2 = my_knns %>% 
  select(-knn,-knn2) %>% 
  unnest(accuracy)

```

```{r categorisation7}
# get best model for each var

my_knns2 %>% 
  ungroup() %>% 
  group_by(variation) %>% 
  arrange(-statistic) %>% 
  slice(1) %>% 
  select(-term,-p.value) %>% 
  kable(digits = 2, caption = 'Table: Best KNN model for each variation.')
```

For 'cselekszenek', the best model isn't very good, but it does something. It uses phonological distance and the largest k, k=15. For 'hotelban', the best model is decent. It also uses the largest k and, curiously, jaccard distance over phonological distance (even though the latter contains more information on how the words compare to one another). For 'lakok', the best model uses k=7 and edit distance. All three best models have an s = .1 which relatively penalises more distant neighbours over closer neighbours.

We can look at the best model for each distance type and variation.

```{r categorisation8}
my_knns2 %>% 
  ungroup() %>% 
  group_by(variation,distance_type) %>% 
  # filter(sim == 'phon') %>% 
  arrange(-statistic) %>% 
  select(-p.value) %>% 
  slice(1) %>% 
  kable(digits = 2, caption = 'Table: Best KNN model for each variation and distance type.')

```

For 'cselekszenek' and 'hotelban', the models don't differ much in accuracy depending on distance. For 'lakok', jaccard distance is markedly more terrible than the others. Phonological distance always helps a little bit over edit distance.

Let's visualise the best KNN model for each variation type.

```{r categorisation9, fig.width = 9, fig.height = 5}
best_params = my_knns2 %>% 
  ungroup() %>% 
  group_by(variation) %>% 
  arrange(-statistic) %>% 
  slice(1) 

my_knns %>% 
  inner_join(best_params) %>% 
  mutate(parameters = glue('{variation},\nk = {var_k},\ns = {var_s},\ndist = {distance_type}')) %>%
  select(parameters,knn2) %>% 
  unnest(knn2) %>% 
  ggplot(aes(category_high,log_odds)) +
  geom_point() +
  theme_bw() +
  geom_smooth(method = 'lm', se = F) +
  facet_wrap( ~ parameters) +
  xlab('weight of "high" category') +
  ylab('log odds of "high/low" category answers in test') +
  ggtitle('KNN models of Wug test')
```

### GCM

We categorise test words based on similarity with training words using the Generalised Context Model. We try `p = [1,2]`, `s = [.1,.3,.5,.7,.9]` and edit distance, jaccard distance, and phonological distance.

```{r categorisation6gcm, echo = T}
# we do the same thing as with the KNNs. If I did this once more I'd need to put it into a function! cheeky

# set up parameters
my_parameters_2 = crossing(
  var_p = c(1,2),
  var_s = c(.1,.3,.5,.7,.9),
  distance_type = c('edit','jaccard','phon'),
  variation = c('lakok/lakom','hotelban/hotelben','cselekszenek/cselekednek')
)

# run models
my_gcms = my_parameters_2 %>% 
  mutate(
    gcm = furrr::future_pmap(list(distance_type,variation,var_p,var_s), ~ wrapGCM(
      dat = word_distance,
      distance_type = ..1,
      my_variation = ..2,
      var_s = ..3,
      var_p = ..4
    ))
  )

# combine with test and calc accuracy
my_gcms %<>% 
  mutate(
    gcm2 = map(gcm,combineWithTest),
    accuracy = map(gcm2,testAccuracy)
  )

my_gcms2 = my_gcms %>% 
  select(-gcm,-gcm2) %>% 
  unnest(accuracy)
```

```{r categorisation7gcm}
# get best model for each var

my_gcms2 %>% 
  ungroup() %>% 
  group_by(variation) %>% 
  arrange(-statistic) %>% 
  select(-p.value) %>% 
  slice(1) %>% 
  kable(digits = 2, caption = 'Table: Best GCM model for each variation.')
```

The GCM models are all pretty good. For 'cselekszenek', the best model uses edit distance and an exponential distance metric. For 'lakok', the best model uses phonological distance and the exponential metric. For 'hotelban' it, again, uses jaccard distance.

```{r categorisation8gcm}
my_gcms2 %>% 
  ungroup() %>% 
  group_by(variation,distance_type) %>% 
  # filter(sim == 'phon') %>% 
  arrange(-statistic) %>% 
  select(-p.value) %>% 
  slice(1) %>% 
  kable(digits = 2, caption = 'Table: Best GCM model for each variation and distance type.')

```

Checking on the best model for all distance types we can see that using jaccard distance gives you a massive but very noisy estimate. For 'hotelban', however, the noise is much smaller and so jaccard wins.

__What are the best models today?__

```{r best_models}
my_knns3 = my_knns2 %>% 
  select(distance_type,var_s,var_p,var_k,variation,estimate,std.error,statistic,sig) %>% 
  mutate(model = 'KNN')

my_gcms3 = my_gcms2 %>%
  select(distance_type,var_s,var_p,variation,estimate,std.error,statistic,sig) %>% 
  mutate(model = 'GCM')

bind_rows(my_gcms3,my_knns3) %>% 
  relocate(model, .before = distance_type) %>% 
  relocate(var_k, .after = var_p) %>% 
  group_by(variation,model) %>%
  arrange(-statistic) %>%
  slice(1) %>% 
  kable(digits = 2, caption = 'Table: Best KNN and GCM model for each variation.')
```

The GCM beats the KNN model for all three variation types, with a solid margin. 

Let's visualise the best model for each variation type.

```{r categorisation9gcm, fig.width = 9, fig.height = 5}
best_params2 = my_gcms2 %>% 
  ungroup() %>% 
  group_by(variation) %>% 
  arrange(-statistic) %>% 
  slice(1) 

gcmplots = my_gcms %>% 
  inner_join(best_params2) %>% 
  mutate(parameters = glue('{variation},\ns = {var_s},\np = {var_p}, \ndist = {distance_type}')) %>%
  select(parameters,gcm2) %>% 
  mutate(
    plot = map2(gcm2,parameters, ~
                {
           ggplot(.x, aes(category_high,log_odds)) +
            geom_point() +
            theme_bw() +
            geom_smooth(method = 'lm', se = F) +
            xlab('weight of "high" category') +
            ylab('log odds of "high/low" category answers in test') +
            ggtitle(.y) +
            geom_rug() +
            ylim(-3.5,3.5)
            
                }
              )  
  )

# plot list using patchwork

p1 = gcmplots$plot[[2]]
p2 = gcmplots$plot[[1]] + 
  # no y axis ticks or labels or title
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
p3 = gcmplots$plot[[3]] + 
  # no y axis ticks or labels or title
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
  
p1 + p2 + p3 + plot_annotation(title = 'Figure: GCM models of Wug test')
  
```

For the two verb patterns (left and right), we see a largely normal distribution of both GCM category weights (x axis) and test answers (y axis). They are correlated, not that much for 'cselekszenek' (left) and a bit better for 'lakok' (right). For the noun pattern (middle), the two categories are much more neatly delineated both in the answers and the GCM weights and the two match relatively well. One exception is a set of verbs in the bottom-right corner that the model sees as relatively "high" but the test answers see as relatively "low".

## Discussion

For the verbs, we get the best results by using overall similarity to everything, more or less. The 'cselekszenek' pattern is noisier than the 'lakok' pattern. This is probably because the former is pretty complicated on its own: some verbs never delete the last vowel, some always do, some do it in some exponents, some pairs differ in meaning, and some verbs actually vary in the same exponent with the same meaning. The test nonce verbs were like these. For the latter, the pattern is much simpler: it only happens in one exponent and a large number of verbs vary.

For 'cselekszenek', the best model uses edit distance, for 'lakok', phonological distance. Note, however, that there is no massive difference in the accuracy of the phonology-based and the edit-distance based model for either variable pattern.

For the noun pattern, people in the Wug task seem to have a pretty clear idea of what nouns are supposed to be doing, which they probably picked up from the ambient language -- in the corpus, nouns also seem to have a clear idea what they are supposed to be doing! A very specific subset of nonce verbs have prediction error on them, meaning that people don't treat them as they should based on their similarity to existing verbs. This merits further investigation but shouldn't be blamed on the categorisation model.

## References

The Wug task:

Berko, Jean. "The child’s learning of English morphology." Word 14, no. 2-3 (1958): 150-177.

The natural class theory of segmental distances:

- Frisch, Stefan. Similarity and frequency in phonology. Northwestern University, 1996.
- Frisch, Stefan A., Janet B. Pierrehumbert, and Michael B. Broe. Similarity avoidance and the OCP. Natural language & linguistic theory 22, no. 1 (2004): 179-228.

Word distances based on segmental distances:

- Albright, Adam, and Bruce Hayes. Rules vs. analogy in English past tenses: A computational/experimental study. Cognition 90, no. 2 (2003): 119-161.
- Dawdy-Hesterberg, Lisa Garnand, and Janet Breckenridge Pierrehumbert. Learnability and generalisation of Arabic broken plural nouns. Language, cognition and neuroscience 29, no. 10 (2014): 1268-1282.

Features:

- Siptár, Péter, and Miklós Törkenczy. The phonology of Hungarian. OUP Oxford, 2000.

Training data:

- Rácz, Péter, and Ágnes Lukács. Morphological convergence and sociolinguistic salience: an experimental study. (2023) [https://osf.io/preprints/psyarxiv/zqwxv](https://osf.io/preprints/psyarxiv/zqwxv).
- Nemeskey, Dávid Márk (2020). Natural Language Processing methods for Language Modeling. PhD thesis. Eötvös Loránd University. [https://hlt.bme.hu/en/resources/webcorpus2](https://hlt.bme.hu/en/resources/webcorpus2)

GCM, KNN:

- Nosofsky, Robert M. "The generalized context model: An exemplar model of classification." Formal approaches in categorization (2011): 18-39.
- Peterson, Leif E. "K-nearest neighbor." Scholarpedia 4, no. 2 (2009): 1883.

The three variable patterns:

- 'cselekszenek/cselekednek': Rácz, Péter, Péter Rebrus, and Miklós Törkenczy. "Attractors of variation in Hungarian inflectional morphology." Corpus Linguistics and Linguistic Theory 17, no. 2 (2021): 287-317.
- 'hotelban/hotelben': Hayes, Bruce, Péter Siptár, Kie Zuraw, and Zsuzsa Londe. "Natural and unnatural constraints in Hungarian vowel harmony." Language (2009): 822-863.
- 'lakok/lakom': Rácz, Péter. "Frequency and prototypicality determine variation in the Hungarian verbal 1 SG. INDEF." Acta Linguistica Academica. An International Journal of Linguistics (Until 2016 Acta Linguistica Hungarica) 66, no. 4 (2019): 601-620.